{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a6c54-6155-4f74-b2c0-574f0b136aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae1a2c-24a4-46b8-91a7-077087587671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths for using psana\n",
    "%env SIT_ROOT=/reg/g/psdm/\n",
    "%env SIT_DATA=/cds/group/psdm/data/\n",
    "%env SIT_PSDM_DATA=/cds/data/psdm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c823d-596a-49c0-90a4-119a827a8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from functools   import reduce\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e765da-33c0-4082-b447-ffeb0fb7a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e094a-21a5-437e-9597-86157b3ee493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import pickle\n",
    "import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a8825-81d5-4654-a706-7e7bfe5cdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepprojection.model import Shi2019Model\n",
    "from deepprojection.encoders.convnet import Shi2019\n",
    "from deepprojection.trainer          import SimpleTrainer      , ConfigTrainer\n",
    "from deepprojection.validator        import SimpleValidator, ConfigValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2cef86-c25f-4dbc-b4e8-7c0d235976e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepprojection.datasets.lite import SPIDataset, SPIOnlineDataset\n",
    "from deepprojection.utils import MetaLog, init_logger, split_dataset, set_seed, NNSize, TorchModelAttributeParser, Config, EpochManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387d2e0-ee62-442b-b20d-54513991b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from image_preprocess_faulty import DatasetPreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82073d3-d8f2-44d7-a5f3-8245e6e3b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ SEED ]]]\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639c075-ebc7-4d54-888e-153db2474558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ CONFIG ]]]\n",
    "timestamp_prev = None\n",
    "## timestamp_prev = \"2022_1129_2150_15\"\n",
    "\n",
    "frac_train     = 0.5\n",
    "frac_validate  = 0.5\n",
    "\n",
    "logs_triplets = True\n",
    "\n",
    "lr = 1e-3\n",
    "## lr = 5e-4\n",
    "\n",
    "## alpha = 0.02\n",
    "## alpha = 0.03336201\n",
    "alpha = 0.05565119\n",
    "## alpha = 0.09283178\n",
    "## alpha = 0.15485274\n",
    "## alpha = 0.25830993\n",
    "## alpha = 0.43088694\n",
    "## alpha = 0.71876273\n",
    "## alpha = 1.1989685\n",
    "## alpha = 2.0\n",
    "\n",
    "size_sample_per_class_train    = 60\n",
    "## size_sample_per_class_train    = 10\n",
    "## size_sample_per_class_train    = 20\n",
    "## size_sample_per_class_train    = 40\n",
    "## size_sample_per_class_train    = 60\n",
    "size_sample_train              = size_sample_per_class_train * 100\n",
    "size_sample_validate           = size_sample_train // 2\n",
    "size_sample_per_class_validate = size_sample_per_class_train // 2\n",
    "size_batch                     = 20\n",
    "trans                          = None\n",
    "\n",
    "# [[[ LOGGING ]]]\n",
    "timestamp = init_logger(log_name = 'train', returns_timestamp = True, saves_log = True)\n",
    "print(timestamp)\n",
    "\n",
    "# Clarify the purpose of this experiment...\n",
    "hostname = socket.gethostname()\n",
    "comments = f\"\"\"\n",
    "            Hostname: {hostname}.\n",
    "\n",
    "            Sample size (train)               : {size_sample_train}\n",
    "            Sample size (validate)            : {size_sample_validate}\n",
    "            Sample size (per class, train)    : {size_sample_per_class_train}\n",
    "            Sample size (per class, validate) : {size_sample_per_class_validate}\n",
    "            Batch  size                       : {size_batch}\n",
    "            Alpha                             : {alpha}\n",
    "            lr                                : {lr}\n",
    "            seed                              : {seed}\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "# Create a metalog to the log file, explaining the purpose of this run...\n",
    "metalog = MetaLog( comments = comments )\n",
    "metalog.report()\n",
    "\n",
    "\n",
    "# [[[ DATASET ]]]\n",
    "# Set up parameters for an experiment...\n",
    "drc_dataset   = 'fastdata'\n",
    "fl_dataset    = '0000.binary.fastdata'    # Raw, just give it a try\n",
    "path_dataset  = os.path.join(drc_dataset, fl_dataset)\n",
    "\n",
    "# Load raw data...\n",
    "with open(path_dataset, 'rb') as fh:\n",
    "    dataset_list = pickle.load(fh)\n",
    "\n",
    "# Split data...\n",
    "data_train   , data_val_and_test = split_dataset(dataset_list     , frac_train   , seed = None)\n",
    "data_validate, data_test         = split_dataset(data_val_and_test, frac_validate, seed = None)\n",
    "\n",
    "# Define the training set\n",
    "dataset_train = SPIOnlineDataset( dataset_list          = data_train, \n",
    "                                  size_sample           = size_sample_train,\n",
    "                                  size_sample_per_class = size_sample_per_class_train, \n",
    "                                  trans                 = trans, \n",
    "                                  seed                  = None, )\n",
    "dataset_train.report()\n",
    "\n",
    "# Define the training set\n",
    "dataset_validate = SPIOnlineDataset( dataset_list          = data_validate, \n",
    "                                     size_sample           = size_sample_train,\n",
    "                                     size_sample_per_class = size_sample_per_class_validate, \n",
    "                                     trans                 = trans, \n",
    "                                     seed                  = None, )\n",
    "dataset_validate.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310957bb-08d4-4f8e-8d22-b0fe5927414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564aecc-c2ac-4ddc-9c09-05c9181f2fcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1b992-98e7-43b5-9e82-98d6f3fd9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset...\n",
    "# Data preprocessing can be lengthy and defined in dataset_preprocess.py\n",
    "img_orig            = dataset_train[0][0][0]   # idx, fetch img\n",
    "dataset_preproc     = DatasetPreprocess(img_orig)\n",
    "trans               = dataset_preproc.config_trans()\n",
    "dataset_train.trans = trans\n",
    "dataset_validate.trans = trans\n",
    "img_trans           = dataset_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fada434-2cc7-48f4-8868-8712f0eaa09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.cache_dataset()\n",
    "dataset_validate.cache_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9e4fc-716c-46c7-a0bd-496e1472ed86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220c16e-248e-4867-838b-729c7c466e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shi2019(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        size_y, size_x = config.size_y, config.size_x\n",
    "        isbias         = config.isbias\n",
    "\n",
    "        # Define the feature extraction layer...\n",
    "        in_channels = 1\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Motif network 1\n",
    "            nn.Conv2d( in_channels  = in_channels,\n",
    "                       out_channels = 5,\n",
    "                       kernel_size  = 5,\n",
    "                       stride       = 1,\n",
    "                       padding      = 0,\n",
    "                       bias         = isbias, ),\n",
    "            nn.BatchNorm2d( num_features = 5 ),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d( kernel_size = 2, \n",
    "                          stride = 2 ),\n",
    "            \n",
    "            # Motif network 2\n",
    "            nn.Conv2d( in_channels  = 5,\n",
    "                       out_channels = 3,\n",
    "                       kernel_size  = 3,\n",
    "                       stride       = 1,\n",
    "                       padding      = 0,\n",
    "                       bias         = isbias, ),\n",
    "            nn.BatchNorm2d( num_features = 3 ),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d( kernel_size = 2, \n",
    "                          stride = 2 ),\n",
    "            \n",
    "            # Motif network 3\n",
    "            nn.Conv2d( in_channels  = 3,\n",
    "                       out_channels = 2,\n",
    "                       kernel_size  = 3,\n",
    "                       stride       = 1,\n",
    "                       padding      = 0,\n",
    "                       bias         = isbias, ),\n",
    "            nn.BatchNorm2d( num_features = 2 ),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d( kernel_size = 2, \n",
    "                          stride = 2 ),\n",
    "        )\n",
    "        \n",
    "        # Fetch all input arguments that define the layer...\n",
    "        attr_parser = TorchModelAttributeParser()\n",
    "        conv_dict = {}\n",
    "        for layer_name, model in self.feature_extractor.named_children():\n",
    "            conv_dict[layer_name] = attr_parser.parse(model)\n",
    "        \n",
    "        # Calculate the output size...\n",
    "        self.feature_size = reduce(lambda x, y: x * y, NNSize(size_y, size_x, in_channels, conv_dict).shape())\n",
    "        \n",
    "        self.squash_to_prob = nn.Sequential(\n",
    "            nn.Linear( in_features = self.feature_size,\n",
    "                       out_features = 2,\n",
    "                       bias = isbias ),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear( in_features = 2,\n",
    "                       out_features = 1,\n",
    "                       bias = isbias ),\n",
    "            nn.Sigmoid(),\n",
    "        )    \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(-1, self.feature_size)\n",
    "        x = self.squash_to_prob(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17affd93-d93b-475b-a20f-d7185b49199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigModel:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # logger.info(f\"___/ Configure Model \\___\")\n",
    "\n",
    "        # Set values of attributes that are not known when obj is created\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "            # logger.info(f\"KV - {k:16s} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73550742-6a3a-400e-ac23-1745e53d1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_y, size_x = img_trans.shape\n",
    "config_model = ConfigModel(size_y = size_y, size_x = size_x, isbias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6634fb1-bebd-447e-8996-3c4e04a76466",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6db74d-6b55-4f68-b1dc-011bb4ea72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Shi2019(config_model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf365e-f538-4f26-a61b-a3ce74cde4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(torch.tensor(img_trans[None, None]).to(device = device, dtype = torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad80983-74ae-4552-babc-32cc3afdbaad",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985ec64-19ca-4aa5-b353-05a7fdfb3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ IMAGE ENCODER ]]]\n",
    "# Config the encoder...\n",
    "size_y, size_x = img_trans.shape[-2:]\n",
    "config_encoder = Config( name   = \"Shi2019\",\n",
    "                         size_y = size_y,\n",
    "                         size_x = size_x,\n",
    "                         isbias = True )\n",
    "encoder = Shi2019(config_encoder)\n",
    "\n",
    "\n",
    "# [[[ MODEL ]]]\n",
    "# Config the model...\n",
    "config_model = Config( name = \"Model\", encoder = encoder, )\n",
    "model = Shi2019Model(config_model)\n",
    "model.init_params(from_timestamp = timestamp_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0163ae5-fcbc-48e8-92ba-09a067885f39",
   "metadata": {},
   "source": [
    "### Config trainer and validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fedc92-24ce-4fa2-bb0d-ffa3ca64198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ CHECKPOINT ]]]\n",
    "drc_cwd          = os.getcwd()\n",
    "DRCCHKPT         = \"chkpts\"\n",
    "prefixpath_chkpt = os.path.join(drc_cwd, DRCCHKPT)\n",
    "fl_chkpt         = f\"{timestamp}.train.chkpt\"\n",
    "path_chkpt       = os.path.join(prefixpath_chkpt, fl_chkpt)\n",
    "\n",
    "\n",
    "# [[[ TRAINER ]]]\n",
    "# Config the trainer...\n",
    "config_train = ConfigTrainer( path_chkpt        = path_chkpt,\n",
    "                              num_workers       = 1,\n",
    "                              batch_size        = size_batch,\n",
    "                              pin_memory        = True,\n",
    "                              shuffle           = False,\n",
    "                              lr                = lr, \n",
    "                              tqdm_disable      = True)\n",
    "trainer = SimpleTrainer(model, dataset_train, config_train)\n",
    "\n",
    "\n",
    "# [[[ VALIDATOR ]]]\n",
    "config_validator = ConfigValidator( path_chkpt        = None,\n",
    "                                    num_workers       = 1,\n",
    "                                    batch_size        = size_batch,\n",
    "                                    pin_memory        = True,\n",
    "                                    shuffle           = False,\n",
    "                                    lr                = lr,\n",
    "                                    tqdm_disable      = True)  # Conv2d input needs one more dim for batch\n",
    "validator = SimpleValidator(model, dataset_validate, config_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a7b7e-55ed-457d-a95a-e4ecaa93208d",
   "metadata": {},
   "source": [
    "### Training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bf304-ca1f-466d-a26b-a0c0cf18846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_hist = []\n",
    "loss_validate_hist = []\n",
    "loss_min_hist = []\n",
    "\n",
    "# [[[ EPOCH MANAGER ]]]\n",
    "epoch_manager = EpochManager( trainer   = trainer,\n",
    "                              validator = validator,\n",
    "                              timestamp = timestamp, )\n",
    "\n",
    "# epoch_manager.set_layer_to_capture(\n",
    "#     module_name_capture_list  = [\"final_conv\"],\n",
    "#     module_layer_capture_list = [torch.nn.ReLU],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e9a55-a183-4a06-9454-192e931da2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_manager.loss_min = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e4436-28d9-495b-bc8d-c2dd88f9e1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "freq_save = 5\n",
    "for epoch in tqdm.tqdm(range(max_epochs), disable=False):\n",
    "    loss_train, loss_validate, loss_min = epoch_manager.run_one_epoch(epoch = epoch, returns_loss = True)\n",
    "    \n",
    "    loss_train_hist.append(loss_train)\n",
    "    loss_validate_hist.append(loss_validate)\n",
    "    loss_min_hist.append(loss_min)\n",
    "\n",
    "    # if epoch % freq_save == 0: \n",
    "    #     epoch_manager.save_model_parameters()\n",
    "    #     epoch_manager.save_model_gradients()\n",
    "    #     epoch_manager.save_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4a950-0339-49aa-a816-d1352fd4b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618f231-6fb9-4820-ae2d-bcfb27407829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana-ml-py3",
   "language": "python",
   "name": "ana-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
