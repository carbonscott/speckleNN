{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680e07ec-9a05-4a09-be4a-dd862aa8b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import socket\n",
    "import pickle\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from deepprojection.datasets.lite    import SPIDataset               , TripletCandidate\n",
    "from deepprojection.model            import OnlineTripletSiameseModel, ConfigSiameseModel\n",
    "from deepprojection.trainer          import OnlineTrainer            , ConfigTrainer\n",
    "from deepprojection.validator        import OnlineLossValidator      , ConfigValidator\n",
    "from deepprojection.encoders.convnet import Hirotaka0122             , ConfigEncoder\n",
    "from deepprojection.utils            import EpochManager             , MetaLog, init_logger, split_dataset, set_seed\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from image_preprocess_faulty_sq import DatasetPreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0a1ea3-a5af-4d49-8cac-e27f96d27c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbff7864-42a8-4d20-aaab-043388fbdb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ SEED ]]]\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dade961-c526-4dff-821c-0011976a7c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_1214_2116_32\n"
     ]
    }
   ],
   "source": [
    "# [[[ LOGGING ]]]\n",
    "timestamp = init_logger(log_name = 'train', returns_timestamp = True, saves_log = False)\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babc2b72-82cc-4413-8aa8-caf70fcfe203",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_train = 0.5\n",
    "frac_validate = 0.5\n",
    "num_sample_train = 100\n",
    "batch_size = 10\n",
    "num_sample_per_label = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1273f8cc-d295-4b03-8aa7-4a81825d75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ DATASET ]]]\n",
    "# Set up parameters for an experiment...\n",
    "drc_dataset   = 'fastdata.h5'\n",
    "fl_dataset    = f'mini.sq.train.relabel.pickle'    # Raw, just give it a try\n",
    "path_dataset  = os.path.join(drc_dataset, fl_dataset)\n",
    "\n",
    "# Load raw data...\n",
    "with open(path_dataset, 'rb') as fh:\n",
    "    dataset_list = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3154bd-9d1a-4add-ba30-c86b48b08d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data...\n",
    "data_train   , data_val_and_test = split_dataset(dataset_list     , frac_train   , seed = None)\n",
    "data_validate, data_test         = split_dataset(data_val_and_test, frac_validate, seed = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ca0bb7-5548-4133-b56c-98a76833a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training set\n",
    "dataset_train = TripletCandidate( dataset_list          = data_train, \n",
    "                                  num_sample            = num_sample_train,\n",
    "                                  num_sample_per_label  = num_sample_per_label, \n",
    "                                  trans                 = None, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59213024-7ad6-4d45-9159-a468e7493659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - ___/ Preprocess Settings \\___\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - Apply Poisson noise. \n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - Apply Gaussian noise. sigma = 0.15.\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - TRANS : Apply random shift. frac_y_shift_max = 0.1, frac_x_shift_max = 0.1.\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - TRANS : Apply cropping.\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - TRANS : Apply downsampling. resize_y = 2, resize_x = 2.\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - TRANS : Apply random rotation. angle = None, center = (24, 24).\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - TRANS : Apply random patching. size_patch_y = 7, size_patch_x = 7.\n",
      "12/14/2022 21:16:37 INFO image_preprocess_faulty_sq          - TRANS : Apply random zoom. max_zoom_percent = 0.4.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess dataset...\n",
    "# Data preprocessing can be lengthy and defined in dataset_preprocess.py\n",
    "img_orig            = dataset_train[0][1][0][0]   # idx, fetch img\n",
    "dataset_preproc     = DatasetPreprocess(img_orig)\n",
    "trans               = dataset_preproc.config_trans()\n",
    "dataset_train.trans = trans\n",
    "img_trans           = dataset_train[0][1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ea7a52-35c6-4166-bf21-f7ff667ff820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b33676-3b28-474a-888c-d11505407b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dataset_train, shuffle = False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef5bc64-0444-45be-b627-ca10d04f382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train_iter = iter(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4542df7d-2147-4562-b743-810c4dd484bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(loader_train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8938227a-14e3-47c7-9f49-bfd9379a0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encode, batch_candidate_nplist, batch_metadata_list = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3be9c3-b7e3-4493-b964-16160fd0002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metadata_list = list(map(list, zip(*batch_metadata_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf6640-cc2c-44c3-bab3-6d906a08a821",
   "metadata": {},
   "source": [
    "#### Pass it through our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d310c0b3-7568-4d0d-beb8-24c7f6da44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2296848-bff5-40ee-b344-09678532940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/14/2022 21:16:39 INFO deepprojection.encoders.convnet     - ___/ Configure Encoder \\___\n",
      "12/14/2022 21:16:39 INFO deepprojection.encoders.convnet     - KV - dim_emb          : 128\n",
      "12/14/2022 21:16:39 INFO deepprojection.encoders.convnet     - KV - size_y           : 48\n",
      "12/14/2022 21:16:39 INFO deepprojection.encoders.convnet     - KV - size_x           : 48\n",
      "12/14/2022 21:16:39 INFO deepprojection.encoders.convnet     - KV - isbias           : True\n",
      "12/14/2022 21:16:39 INFO deepprojection.model                - ___/ Configure Siamese Model \\___\n",
      "12/14/2022 21:16:39 INFO deepprojection.model                - KV - alpha            : 0.05\n",
      "12/14/2022 21:16:39 INFO deepprojection.model                - KV - encoder          : Hirotaka0122(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): PReLU(num_parameters=1)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (embed): Sequential(\n",
      "    (0): Linear(in_features=5184, out_features=512, bias=True)\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OnlineTripletSiameseModel(\n",
       "  (encoder): Hirotaka0122(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (5): PReLU(num_parameters=1)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embed): Sequential(\n",
       "      (0): Linear(in_features=5184, out_features=512, bias=True)\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [[[ IMAGE ENCODER ]]]\n",
    "# Config the encoder...\n",
    "dim_emb        = 128\n",
    "size_y, size_x = img_trans.shape[-2:]\n",
    "config_encoder = ConfigEncoder( dim_emb = dim_emb,\n",
    "                                size_y  = size_y,\n",
    "                                size_x  = size_x,\n",
    "                                isbias  = True )\n",
    "encoder = Hirotaka0122(config_encoder)\n",
    "\n",
    "\n",
    "# [[[ MODEL ]]]\n",
    "# Config the model...\n",
    "alpha = 0.05\n",
    "timestamp_prev = None\n",
    "config_siamese = ConfigSiameseModel( alpha = alpha, encoder = encoder, )\n",
    "model = OnlineTripletSiameseModel(config_siamese)\n",
    "model.init_params(from_timestamp = timestamp_prev)\n",
    "model.to(device, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74821e-edd8-43c1-ad47-1fba9d2ef645",
   "metadata": {},
   "source": [
    "#### Select semi-hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7deae-dbec-497f-b80e-5d78e81d6f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec58382-ae92-4ac7-a9ce-259ac0d1e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(loader_train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12ae54-470f-4e5c-b30b-bb6ebd3b4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encode, batch_candidate_nplist, batch_metadata_list = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca903ffe-5b78-45c8-9b12-d896937f2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885fc-d629-4e4c-a63e-8e16d21903c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.encode_to_label_dict[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8880e1-748e-40f1-b225-be36e45b4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metadata_list = list(map(list, zip(*batch_metadata_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12267b-ec22-4683-a5fc-1d27081252ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c585c5-aaf0-4791-b657-6cc01edf37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encode = batch_encode.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91d7ebbd-d0cb-4cbc-8ded-6610b05759ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_candidate_nplist = batch_candidate_nplist.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3311a67c-2015-4e1d-a4d7-2360c5a2657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 1BR1 2(2) 75, 1BR1 2(4) 58, 6WJJ 1(1) 36; semi-hard 4.023236e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 6RAO 1(1) 45, 6RAO 1(1) 60, 1BR1 2(3) 95; semi-hard 3.301352e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 7AR9 2(3) 88, 7AR9 2(3) 22, 6VM1 1(1) 39; semi-hard 4.185802e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 7DQD 1(1) 48, 7DQD 1(1) 12, 6VM1 2(3) 82; semi-hard 3.464109e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 7KDV 1(1) 49, 7KDV 1(1) 54, 6VM1 2(3) 40; semi-hard 4.469410e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 6WJJ 1(1) 99, 6WJJ 1(1) 36, 6VM1 2(4) 66; semi-hard 4.386210e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 7A5P 1(1) 67, 7A5P 1(1) 32, 1BR1 2(2) 20; semi-hard 2.317768e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 6VM1 1(1) 85, 6VM1 1(1) 71, 1BR1 2(2) 31; semi-hard 1.821345e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 6Z86 1(1) 97, 6Z86 1(1) 41, 1BR1 2(4) 11; semi-hard 2.221656e-02\n",
      "12/14/2022 21:16:41 INFO deepprojection.model                - DATA - 6VM1 2(4) 48, 6VM1 2(2) 66, 6WJJ 1(1) 48; semi-hard 1.782167e-02\n"
     ]
    }
   ],
   "source": [
    "triplet_list, dist_list = model.select_semi_hard(batch_encode, batch_candidate_nplist, dataset_train.encode_to_label_dict, batch_metadata_list, logs_triplets = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79990c6f-a17e-464f-baed-00f7b71157a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 2), (0, 11), (5, 11)),\n",
       " ((1, 6), (1, 11), (0, 4)),\n",
       " ((2, 10), (2, 9), (7, 4)),\n",
       " ((3, 1), (3, 6), (9, 13)),\n",
       " ((4, 11), (4, 14), (9, 0)),\n",
       " ((5, 7), (5, 11), (9, 5)),\n",
       " ((6, 1), (6, 11), (0, 6)),\n",
       " ((7, 9), (7, 1), (0, 3)),\n",
       " ((8, 11), (8, 3), (0, 10)),\n",
       " ((9, 1), (9, 8), (5, 0))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58cfae-7535-4a8b-a2a4-aff8c76c9d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba0e1f-e302-4b07-8116-eb9dffea9f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9dbd2-9ec5-4c00-bbeb-cde79184c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"4 7NP3 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea32ba-20bc-419b-8bad-b01b7d0944d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce789cd6-71b4-4de6-833d-4d8a9c83d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_candidate_nplist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab9c45-90e8-49d3-be7f-7fa83f111319",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c594909-0cbd-4817-a701-e52c6bad9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ triplet[0] for triplet in triplet_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1aae9-0652-4940-b5ed-a9ed00ed961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_candidate_nplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84873b-0634-4b90-b562-769ef043d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_candidate_nplist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbde74-22f4-4fab-834c-70d345a12528",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_a = batch_candidate_nplist.view(-1, *batch_candidate_nplist.shape[-3:])[ [ triplet[0][0] * batch_candidate_nplist.shape[0] + triplet[0][1] for triplet in triplet_list ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49496d4f-c761-4cbc-95bf-be1b179e32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_p = batch_candidate_nplist.view(-1, *batch_candidate_nplist.shape[-3:])[ [ triplet[1][0] * batch_candidate_nplist.shape[0] + triplet[1][1] for triplet in triplet_list ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a37630-77af-4ec9-8767-5a3391b1d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_n = batch_candidate_nplist.view(-1, *batch_candidate_nplist.shape[-3:])[ [ triplet[2][0] * batch_candidate_nplist.shape[0] + triplet[2][1] for triplet in triplet_list ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5cc2a-bc8e-4c17-9071-32c42a7f4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(batch_a, batch_p, batch_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128042e-48aa-4e5e-a5ab-c77274993261",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_a2 = batch_candidate_nplist.view(-1, *batch_candidate_nplist.shape[-3:])[ [ idx_encode * batch_candidate_nplist.shape[0] + idx_a for (idx_encode, idx_a), _, _ in triplet_list ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21186a-da4e-4304-934b-5e5ae9ae027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_a == batch_a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537494c-a42e-4fd8-a2f2-2ed94aeb1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.rand((10,20), device = device) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2b7de-e511-4e31-9fc2-d814f132e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.any(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e71c1-0d63-4a5e-aaf1-71c50c7fc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.any(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1f675-8e85-48e1-a416-e1b61f7121f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_data.any(dim = -1)):\n",
    "    print(i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba7483-9503-4bd4-9d1a-e76c265fff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ i for i, data in enumerate(test_data.any(dim = -1)) if data == False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce9d30-cd7f-405d-9505-0ed41c048ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_ary = np.array(['asdf', 'sadf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6f14d-9154-4e73-8136-ff48f8ae7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(test_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd6657-a461-4681-88c7-5534dd625ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana-ml-py3",
   "language": "python",
   "name": "ana-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
